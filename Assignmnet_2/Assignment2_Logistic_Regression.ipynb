{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: otter-grader in /Users/junwei/anaconda3/lib/python3.12/site-packages (6.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (8.1.7)\n",
      "Requirement already satisfied: dill>=0.3.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (0.3.8)\n",
      "Requirement already satisfied: fica>=0.4.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (0.4.1)\n",
      "Requirement already satisfied: ipylab<2.0.0,>=1.0.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (1.0.0)\n",
      "Requirement already satisfied: ipython in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (8.27.0)\n",
      "Requirement already satisfied: ipywidgets<9.0.0,>=8.1.5 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (8.1.5)\n",
      "Requirement already satisfied: jinja2<4.0,>=3.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (3.1.4)\n",
      "Requirement already satisfied: jupytext<2.0.0,>=1.16.4 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (1.16.6)\n",
      "Requirement already satisfied: nbconvert>=6.0.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.0.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (5.10.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (2.2.2)\n",
      "Requirement already satisfied: python-on-whales<1.0.0,>=0.72.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (0.75.1)\n",
      "Requirement already satisfied: pyyaml<7,>=6 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (6.0.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.16.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from otter-grader) (1.17.2)\n",
      "Requirement already satisfied: docutils in /Users/junwei/anaconda3/lib/python3.12/site-packages (from fica>=0.4.1->otter-grader) (0.18.1)\n",
      "Requirement already satisfied: sphinx in /Users/junwei/anaconda3/lib/python3.12/site-packages (from fica>=0.4.1->otter-grader) (7.3.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (0.2.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (3.0.13)\n",
      "Requirement already satisfied: decorator in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipython->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipython->otter-grader) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipython->otter-grader) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipython->otter-grader) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipython->otter-grader) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipython->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from ipython->otter-grader) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jinja2<4.0,>=3.1->otter-grader) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (0.3.0)\n",
      "Requirement already satisfied: packaging in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (24.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.2.1)\n",
      "Requirement already satisfied: playwright in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.49.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbformat>=5.0.0->otter-grader) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbformat>=5.0.0->otter-grader) (4.23.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->otter-grader) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->otter-grader) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->otter-grader) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->otter-grader) (2023.3)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/junwei/anaconda3/lib/python3.12/site-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->otter-grader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->otter-grader) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->otter-grader) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->otter-grader) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/junwei/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jupyter-core>=4.7->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.10.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=1.0->jupytext<2.0.0,>=1.16.4->otter-grader) (0.1.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (8.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython->otter-grader) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/junwei/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->otter-grader) (0.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (2.5)\n",
      "Requirement already satisfied: greenlet==3.1.1 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.1.1)\n",
      "Requirement already satisfied: pyee==12.0.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (12.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.3)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.11.0)\n",
      "Requirement already satisfied: alabaster~=0.7.14 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (0.7.16)\n",
      "Requirement already satisfied: imagesize>=1.3 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.4.1)\n",
      "Requirement already satisfied: executing in /Users/junwei/anaconda3/lib/python3.12/site-packages (from stack-data->ipython->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/junwei/anaconda3/lib/python3.12/site-packages (from stack-data->ipython->otter-grader) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/junwei/anaconda3/lib/python3.12/site-packages (from stack-data->ipython->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install otter-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Assignment2_Logistic_Regression.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS385/CSD3185/CSD3186: Assignment 2 Logistic Regression\n",
    "\n",
    "## Deliverables\n",
    "Your submission for this assignment should be __ONE__ file - a zip file generated by the `grader.export(_)` function down below under 'Submission'. This function will auto create the zip file which contains this particular completed notebook file for you.  \n",
    "\n",
    "Subsequently, rename your zip file like this: __coursecode_A2_your_full_name.zip__  \n",
    "Eg. CS385_A2_john_doe.zip  \n",
    "\n",
    "To complete this assignment, you should follow instructions in Section Tasks.\n",
    "\n",
    "## IMPORTANT! READ THIS BEFORE STARTING...\n",
    "- DO NOT delete existing cells, but you can add more cells in between.\n",
    "- DO NOT modify the content of the existing cells unless otherwise stated.\n",
    "- Run the cell with `grader.check(_)` to check your solutions whenever you have completed each tasks.\n",
    "- Follow the file naming convention for the zip file as spelled out above strictly.\n",
    "- DO NOT rename this notebook file. It shall be 'Assignment2_Logistic_Regression.ipynb'. \n",
    "\n",
    "Please adhere strictly to the instructions as stated above as failure to do so might result in deduction of marks by the autograder.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Covered\n",
    "**Logistic Regression** is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable takes on one of two possible values, typically coded as 1 (e.g., yes, success, etc.) or 0 (e.g., no, failure, etc.). The logistic regression model estimates the probability of the dependent variable being 1, denoted as $P(Y=1)$, based on the input features ($X$).\n",
    "\n",
    "In this notebook, We'll use the <a href=\"https://archive.ics.uci.edu/dataset/222/bank+marketing\">Bank Marketing dataset</a> from the UCI Machine Learning Repository, which focuses on direct marketing campaigns conducted via phone calls by a Portuguese banking institution. The objective is to predict whether a client will subscribe to a term deposit (coded as 1 for yes or 0 for no).\n",
    "\n",
    "**Notebook Structure**:\n",
    "1. Loading and Inspecting the Dataset [_5 marks_]\n",
    "2. Exploring the Dataset (Part I) [_5 marks_]\n",
    "3. Exploring the Dataset (part II) [_15 marks_]\n",
    "4. Create Dummy variables \n",
    "5. Random Over-sampling of the Minority Class [_25 marks_]\n",
    "6. Logistic Regression Model Fitting [_20 marks_]\n",
    "7. Grid Searching for Hyperparameter Selection [_30 marks_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Overview**   \n",
    "|**Variable**     |**Description**                         |**Type**                                     |\n",
    "|:-----------------------|:-------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------|\n",
    "| `age`                | Age                                                                                                                     | Numeric                                                                                   |\n",
    "| `job`                | Type of job                                                                                                             | Categorical: “admin”, “blue-collar”, “entrepreneur”, “housemaid”, “management”, “retired”, “self-employed”, “services”, “student”, “technician”, “unemployed”, “unknown” |\n",
    "| `marital`            | Marital status                                                                                                          | Categorical: “divorced”, “married”, “single”, “unknown”                                   |\n",
    "| `education`          | Education level                                                                                                         | Categorical: “basic.4y”, “basic.6y”, “basic.9y”, “high.school”, “illiterate”, “professional.course”, “university.degree”, “unknown” |\n",
    "| `default`            | Has credit in default?                                                                                                  | Categorical: “no”, “yes”, “unknown”                                                      |\n",
    "| `housing`            | Has housing loan?                                                                                                       | Categorical: “no”, “yes”, “unknown”                                                      |\n",
    "| `loan`               | Has personal loan?                                                                                                      | Categorical: “no”, “yes”, “unknown”                                                      |\n",
    "| `contact`            | Contact communication type                                                                                              | Categorical: “cellular”, “telephone”                                                     |\n",
    "| `month`              | Last contact month of year                                                                                              | Categorical: “jan”, “feb”, “mar”, …, “nov”, “dec”                                        |\n",
    "| `day_of_week`        | Last contact day of the week                                                                                            | Categorical: “mon”, “tue”, “wed”, “thu”, “fri”                                           |\n",
    "| `duration`           | Last contact duration in seconds. Note: affects the output target and should be discarded for realistic models.          | Numeric                                                                                   |\n",
    "| `campaign`           | Number of contacts performed during this campaign for this client                                                       | Numeric                                                                                   |\n",
    "| `pdays`              | Number of days since last contact from a previous campaign (999 = not previously contacted)                             | Numeric                                                                                   |\n",
    "| `previous`           | Number of contacts performed before this campaign for this client                                                       | Numeric                                                                                   |\n",
    "| `poutcome`           | Outcome of the previous marketing campaign                                                                              | Categorical: “failure”, “nonexistent”, “success”                                         |\n",
    "| `emp.var.rate`       | Employment variation rate                                                                                               | Numeric                                                                                   |\n",
    "| `cons.price.idx`     | Consumer price index                                                                                                   | Numeric                                                                                   |\n",
    "| `cons.conf.idx`      | Consumer confidence index                                                                                              | Numeric                                                                                   |\n",
    "| `euribor3m`          | Euribor 3-month rate                                                                                                   | Numeric                                                                                   |\n",
    "| `nr.employed`        | Number of employees                                                                                                    | Numeric                                                                                   |\n",
    "| **Target variable**  | **Description**                                                                                                         | **Type**                                                                                  |\n",
    "| `y`                  | Has the client subscribed to a term deposit?                                                                           | Binary: “1” (Yes), “0” (No)                                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provides the bank customers’ information. It includes 41,188 records and 21 fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** To ensure the grid search section in Part 7 runs without errors, please upgrade your scikit-learn package to version 1.6.1. You only need to run the following command once. After successfully upgrading, you can comment out the line to avoid reinstallation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.6.1 in /Users/junwei/.local/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/junwei/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "#plt.rc(\"font\", size=14)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "#sns.set(style=\"white\")\n",
    "#sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Inspecting the Dataset\n",
    "\n",
    "In this section, we will load the dataset into a pandas DataFrame and perform a quick inspection. This step ensures the data is properly loaded and gives an initial understanding of its structure.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Load the dataset <code>\"banking.csv\"</code> into a pandas DataFrame called <code>data</code>. \n",
    "- Display the first 5 rows of <code>data</code> using the <code>head()</code> method.\n",
    "- Provide summary statistics for numeric columns in the DataFrame using the `describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   age          job  marital          education  default housing loan  \\\n",
      "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
      "1   53   technician  married            unknown       no      no   no   \n",
      "2   28   management   single  university.degree       no     yes   no   \n",
      "3   39     services  married        high.school       no      no   no   \n",
      "4   55      retired  married           basic.4y       no     yes   no   \n",
      "\n",
      "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
      "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
      "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
      "2  cellular   jun         thu  ...         3      6         2      success   \n",
      "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
      "4  cellular   aug         fri  ...         1      3         1      success   \n",
      "\n",
      "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
      "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
      "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
      "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
      "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
      "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "               age      duration      campaign         pdays      previous  \\\n",
      "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000   \n",
      "mean      40.02406    258.285010      2.567593    962.475454      0.172963   \n",
      "std       10.42125    259.279249      2.770014    186.910907      0.494901   \n",
      "min       17.00000      0.000000      1.000000      0.000000      0.000000   \n",
      "25%       32.00000    102.000000      1.000000    999.000000      0.000000   \n",
      "50%       38.00000    180.000000      2.000000    999.000000      0.000000   \n",
      "75%       47.00000    319.000000      3.000000    999.000000      0.000000   \n",
      "max       98.00000   4918.000000     56.000000    999.000000      7.000000   \n",
      "\n",
      "       emp_var_rate  cons_price_idx  cons_conf_idx     euribor3m  \\\n",
      "count  41188.000000    41188.000000   41188.000000  41188.000000   \n",
      "mean       0.081886       93.575664     -40.502600      3.621291   \n",
      "std        1.570960        0.578840       4.628198      1.734447   \n",
      "min       -3.400000       92.201000     -50.800000      0.634000   \n",
      "25%       -1.800000       93.075000     -42.700000      1.344000   \n",
      "50%        1.100000       93.749000     -41.800000      4.857000   \n",
      "75%        1.400000       93.994000     -36.400000      4.961000   \n",
      "max        1.400000       94.767000     -26.900000      5.045000   \n",
      "\n",
      "        nr_employed             y  \n",
      "count  41188.000000  41188.000000  \n",
      "mean    5167.035911      0.112654  \n",
      "std       72.251528      0.316173  \n",
      "min     4963.600000      0.000000  \n",
      "25%     5099.100000      0.000000  \n",
      "50%     5191.000000      0.000000  \n",
      "75%     5228.100000      0.000000  \n",
      "max     5228.100000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Replace ... with your code\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"banking.csv\")\n",
    "\n",
    "# Display the first 5 rows\n",
    "head_data = data[:5]\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(head_data)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Provide summary statisitcis for numberical columns in the dataframe\n",
    "print(\"Summary statistics for numerical columns:\")\n",
    "data_description = data.describe()\n",
    "print(data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>task1</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "task1 results: All test cases passed!"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"task1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Dataset (part i)\n",
    "In this section, we will explore the dataset further to identify missing values, understand categorical variables, and examine the structure of the data. This step helps in identifying potential issues and gaining insights into the dataset.\n",
    "\n",
    "### Instructions\n",
    "- **Identify Missing Values**: Use an appropriate pandas method to calculate and display the number of missing values in each column.\n",
    "- **Understand Dataset Structure**: Verify the dataset's shape by printing the number of rows and columns.\n",
    "- **Check Unique Categories**: Display the unique categories in the `education` column to understand its categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "\n",
      "Shape of the DataFrame:\n",
      "(41188, 21)\n",
      "\n",
      "Unique categories in the 'education' column:\n",
      "['basic.4y' 'unknown' 'university.degree' 'high.school' 'basic.9y'\n",
      " 'professional.course' 'basic.6y' 'illiterate']\n"
     ]
    }
   ],
   "source": [
    "# Replace ... with your code\n",
    "# Inspect the number of missing values in each column\n",
    "missing_values = data.isna().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Shape of the dataframe\n",
    "data_shape = data.shape\n",
    "print(\"\\nShape of the DataFrame:\")\n",
    "print(data_shape)\n",
    "\n",
    "# Check how many categories are in the education column\n",
    "education_categories = data[\"education\"].unique()\n",
    "print(\"\\nUnique categories in the 'education' column:\")\n",
    "print(education_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>task2</pre></strong> passed! 🎉</p>"
      ],
      "text/plain": [
       "task2 results: All test cases passed!"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"task2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The education column of the dataset has many categories and we need to reduce the categories for a better modelling. Let us group “basic.4y”, “basic.9y” and “basic.6y” together and call them “basic”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grouping, it reduced to six education categories: 'Basic', 'unknown', 'university.degree', 'high.school','professional.course', 'illiterate'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the Dataset (part ii)\n",
    "In this section, we will analyze the target variable y to understand its distribution and derive some basic insights. This analysis helps assess class imbalance and potential relationships between the target and other variables.\n",
    "\n",
    "## Instructions\n",
    "- Display the value counts of the target variable y using the `value_counts()` method\n",
    "- Calculate the number and percentage of rows where y is 0 (no subscription) and 1 (subscription).\n",
    "- Display the mean of numeric columns grouped by the target variable y using the `groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a count plot for the target variable\n",
    "sns.countplot(x='y', data=data, palette='hls')  \n",
    "plt.title(\"Count Plot for Target Variable 'y'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for the target variable 'y':\n",
      "y\n",
      "0    36548\n",
      "1     4640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace ... with your code\n",
    "# Display value counts for the target variable\n",
    "y_value_counts = data[\"y\"].value_counts()\n",
    "print(\"Value counts for the target variable 'y':\")\n",
    "print(y_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of no subscription: 88.73%\n",
      "Percentage of subscription: 11.27%\n"
     ]
    }
   ],
   "source": [
    "# Replace ... with your code\n",
    "# Calculate subscription statistics\n",
    "count_no_sub = y_value_counts[0]\n",
    "count_sub = y_value_counts[1]\n",
    "\n",
    "pct_of_no_sub = y_value_counts[0] / y_value_counts.sum()\n",
    "pct_of_sub = y_value_counts[1] / y_value_counts.sum()\n",
    "\n",
    "print(f\"Percentage of no subscription: {pct_of_no_sub * 100:.2f}%\")\n",
    "print(f\"Percentage of subscription: {pct_of_sub * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.911185</td>\n",
       "      <td>220.844807</td>\n",
       "      <td>2.633085</td>\n",
       "      <td>984.113878</td>\n",
       "      <td>0.132374</td>\n",
       "      <td>0.248875</td>\n",
       "      <td>93.603757</td>\n",
       "      <td>-40.593097</td>\n",
       "      <td>3.811491</td>\n",
       "      <td>5176.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.913147</td>\n",
       "      <td>553.191164</td>\n",
       "      <td>2.051724</td>\n",
       "      <td>792.035560</td>\n",
       "      <td>0.492672</td>\n",
       "      <td>-1.233448</td>\n",
       "      <td>93.354386</td>\n",
       "      <td>-39.789784</td>\n",
       "      <td>2.123135</td>\n",
       "      <td>5095.115991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age    duration  campaign       pdays  previous  emp_var_rate  \\\n",
       "y                                                                        \n",
       "0  39.911185  220.844807  2.633085  984.113878  0.132374      0.248875   \n",
       "1  40.913147  553.191164  2.051724  792.035560  0.492672     -1.233448   \n",
       "\n",
       "   cons_price_idx  cons_conf_idx  euribor3m  nr_employed  \n",
       "y                                                         \n",
       "0       93.603757     -40.593097   3.811491  5176.166600  \n",
       "1       93.354386     -39.789784   2.123135  5095.115991  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace ... with your code\n",
    "# Display the mean of numeric columns grouped by the target variable\n",
    "grouped_means = data.select_dtypes([np.number]).groupby(by=[\"y\"]).mean()\n",
    "grouped_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>task3</pre></strong> passed! 🎉</p>"
      ],
      "text/plain": [
       "task3 results: All test cases passed!"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"task3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the outputs above, what are some observations? Please share some of your findings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Our classes are imbalanced, and the ratio of no-subscription to subscription instances is 89:11.\n",
    "- The average age of customers who bought the term deposit is higher than that of the customers who didn’t.  \n",
    "- The pdays (days since the customer was last contacted) is understandably lower for the customers who bought it. The lower the pdays, the better the memory of the last call and hence the better chances of a sale.  \n",
    "- Surprisingly, campaigns (number of contacts or calls made during the current campaign) are lower for customers who bought the term deposit.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. **Create dummy variables**  \n",
    "In this section, we will learn how to transform categorical variables into dummy variables, which are binary representations. **The codes in this section are provided and no modification is required.** Dummy variables are essential for preparing data for machine learning models that require numeric input.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'green', 'red', 'green']\n",
    "})\n",
    "\n",
    "# Create dummy variables\n",
    "dummy_df = pd.get_dummies(data['color'], prefix='color')\n",
    "\n",
    "print(dummy_df)\n",
    "\n",
    "```\n",
    "**Output:**\n",
    "```\n",
    "   color_blue  color_green  color_red\n",
    "0       False        False       True\n",
    "1        True        False      False\n",
    "2       False         True      False\n",
    "3       False        False       True\n",
    "4       False         True      False\n",
    "```\n",
    "**Explanation:**\n",
    "* pd.get_dummies() takes the color column and creates a binary column for each unique category (blue, green, red).\n",
    "* Each row has a True under the corresponding color and False for the rest. You can change the dtype to int so that it returns 1 and 0 for each column, for example:\n",
    "  ```python\n",
    "  dummy_df = pd.get_dummies(data['color'], prefix='color', dtype=int)\n",
    "  ```\n",
    "* The prefix='color' argument ensures that the dummy columns are prefixed with the word color.\n",
    "\n",
    "This approach is widely used to convert categorical variables into a format suitable for machine learning models. To learn more about pd.get_dummies() and its usage, refer to the [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(data[var], prefix=var, dtype = int) # by default, it returns True or False\n",
    "    data1=data.join(cat_list)\n",
    "    \n",
    "    \n",
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "data_vars=data1.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final data columns will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate',\n",
       "       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y',\n",
       "       'poutcome_failure', 'poutcome_nonexistent', 'poutcome_success'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final=data1[to_keep]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>59</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.866</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>31</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.860</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>48</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>92.431</td>\n",
       "      <td>-26.9</td>\n",
       "      <td>0.742</td>\n",
       "      <td>5017.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>25</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.859</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  duration  campaign  pdays  previous  emp_var_rate  cons_price_idx  \\\n",
       "0       44       210         1    999         0           1.4          93.444   \n",
       "1       53       138         1    999         0          -0.1          93.200   \n",
       "2       28       339         3      6         2          -1.7          94.055   \n",
       "3       39       185         2    999         0          -1.8          93.075   \n",
       "4       55       137         1      3         1          -2.9          92.201   \n",
       "...    ...       ...       ...    ...       ...           ...             ...   \n",
       "41183   59       222         1    999         0           1.4          94.465   \n",
       "41184   31       196         2    999         0           1.1          93.994   \n",
       "41185   42        62         3    999         0           1.1          93.994   \n",
       "41186   48       200         2    999         0          -3.4          92.431   \n",
       "41187   25       112         4    999         0           1.1          93.994   \n",
       "\n",
       "       cons_conf_idx  euribor3m  nr_employed  y  poutcome_failure  \\\n",
       "0              -36.1      4.963       5228.1  0                 0   \n",
       "1              -42.0      4.021       5195.8  0                 0   \n",
       "2              -39.8      0.729       4991.6  1                 0   \n",
       "3              -47.1      1.405       5099.1  0                 0   \n",
       "4              -31.4      0.869       5076.2  1                 0   \n",
       "...              ...        ...          ... ..               ...   \n",
       "41183          -41.8      4.866       5228.1  0                 0   \n",
       "41184          -36.4      4.860       5191.0  0                 0   \n",
       "41185          -36.4      4.857       5191.0  0                 0   \n",
       "41186          -26.9      0.742       5017.5  0                 0   \n",
       "41187          -36.4      4.859       5191.0  0                 0   \n",
       "\n",
       "       poutcome_nonexistent  poutcome_success  \n",
       "0                         1                 0  \n",
       "1                         1                 0  \n",
       "2                         0                 1  \n",
       "3                         1                 0  \n",
       "4                         0                 1  \n",
       "...                     ...               ...  \n",
       "41183                     1                 0  \n",
       "41184                     1                 0  \n",
       "41185                     1                 0  \n",
       "41186                     1                 0  \n",
       "41187                     1                 0  \n",
       "\n",
       "[41188 rows x 14 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. **Random Over-sampling the minority class**  \n",
    "In this section, we will learn about over-sampling, which is the process of randomly duplicating observations from the minority class to achieve a balanced dataset.\n",
    "\n",
    "The most common approach to over-sampling is to resample with replacement. Here's how to proceed:\n",
    "\n",
    "- Import the necessary resampling module from Scikit-Learn.\n",
    "- Split the data into training and testing sets using train_test_split.\n",
    "- Separate the majority and minority classes in the training data.\n",
    "- Upsample the minority class by randomly duplicating its samples.\n",
    "- Combine the upsampled minority class with the majority class to create a balanced dataset.\n",
    "- Split the data back into features (X_train) and target (y_train).\n",
    "- Applied `StandardScaler` to standardize both training and testing features to get `X_train_scaled` and `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resample module and Scaler \n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Split data into X and y\n",
    "X = data[data.columns[:-1]]\n",
    "y = data[data.columns[-1:]]\n",
    "\n",
    "# Split data into training and testing sets using train_test_split\n",
    "X_train_bef, X_test, y_train_bef, y_test = train_test_split(X, y, test_size=0.3, random_state=100) \n",
    "\n",
    "# Combine X_train and y_train\n",
    "train_data = pd.concat([X_train_bef, y_train_bef], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Separate majority and minority classes\n",
    "# majority: train data with y == 0, minority: train data with y == 1\n",
    "majority = data.groupby([\"y\"]).get_group(0)\n",
    "minority = data.groupby([\"y\"]).get_group(1)\n",
    "\n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority,\n",
    "                              replace=True,   # Sample with replacement\n",
    "                              n_samples=len(majority),  # Match majority class size\n",
    "                              random_state=0)  # Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Combine majority and upsampled minority\n",
    "upsampled_data = majority\n",
    "upsampled_data.add(minority_upsampled)\n",
    "\n",
    "# Split back into features and target\n",
    "X_train = upsampled_data[upsampled_data.columns[:-1]]\n",
    "y_train = upsampled_data[upsampled_data.columns[-1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'blue-collar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gd/6gqnpd597xs37gfhsfd8kq680000gp/T/ipykernel_17898/842550774.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replace ... with your code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Scale features in X_train and X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2940\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n\u001b[1;32m   1058\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'blue-collar'"
     ]
    }
   ],
   "source": [
    "# Replace ... with your code\n",
    "# Scale features in X_train and X_test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit(X_train)\n",
    "X_test_scaled = scaler.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You may have noticed that the over-sampling was performed only on the training data. This is important because by over-sampling only the training set, we ensure that no information from the test data is used to create synthetic observations. This prevents any potential data leakage, where information from the test set might influence the model training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Random over-sampling is a straightforward yet powerful technique for addressing class imbalance. However, it can sometimes lead to overfitting, as the model may memorize duplicated samples rather than learning to generalize effectively. To mitigate this, consider combining random over-sampling with more sophisticated approaches like SMOTE (Synthetic Minority Over-sampling Technique), which generates synthetic samples instead of duplicating existing ones. you can explore a variety of techniques and strategies in future projects when dealing with imbalanced data. Below are some popular methods for addressing class imbalance:\n",
    "\n",
    "### Alternative Resampling Techniques:\n",
    "\n",
    "**Under-sampling the Majority Class:** This involves reducing the number of samples in the majority class to match the size of the minority class. While it can balance the dataset, it risks discarding potentially valuable information from the majority class.\n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique):** Unlike random over-sampling, SMOTE creates synthetic samples for the minority class by interpolating between existing samples. This helps to reduce the risk of overfitting.\n",
    "\n",
    "**ADASYN (Adaptive Synthetic Sampling):** Similar to SMOTE, ADASYN focuses on generating more synthetic samples in regions where the minority class is under-represented, improving the classifier's performance on difficult-to-learn samples.\n",
    "\n",
    "**Cluster-based Over-sampling:** Groups data into clusters before over-sampling the minority class within each cluster, ensuring better representation and diversity of the synthetic samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. **Logistic Regression Model Fitting**\n",
    "In this section, we will fit a logistic regression model to the training data and evaluate its performance on the test data. \n",
    "\n",
    "### Instructions\n",
    "- Instantiate the logistic regression model using `LogisticRegression()`.\n",
    "- Train the model using the `fit` method on the training data (`X_train_scaled` and `y_train`).\n",
    "- Make predictions on the test data (`X_test_scaled`) using the `predict` method.\n",
    "- Calculate the model's accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Instantiate the logistic regression model\n",
    "logreg = ...\n",
    "\n",
    "# Fit the model to the training data\n",
    "...\n",
    "\n",
    "# Make predictions on the test and display the accuracy\n",
    "y_pred = ...\n",
    "\n",
    "# Calculate and display the accuracy\n",
    "accuracy = ...\n",
    "print(f'Accuracy of logistic regression classifier on test set: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Grid Searching for selecting hyperparameters**\n",
    "\n",
    "Our initial logistic regression model achieved an accuracy of approximately 85%, which was a promising start. To further explore potential improvements, we will conduct a grid search to fine-tune the hyperparameters of the model.\n",
    "\n",
    "A **grid search** systematically tests combinations of hyperparameter values to determine the best-performing model. In this case, we'll focus on two hyperparameters of the logistic regression model:\n",
    "1. **Penalty**: Regularization technique used to avoid overfitting.\n",
    "2. **C**: Inverse of regularization strength (smaller values specify stronger regularization).\n",
    "\n",
    "### **Instructions**\n",
    "- Combine the hyperparameter lists of `penalty` and `C` into a dictionary using `dict()`, with keys as hyperparameter names and values as the corresponding lists.\n",
    "- Instantiate `GridSearchCV` with the attributes set as `estimator = lgr`, `param_grid = param_grid` and store this instance in the `grid_search` variable\n",
    "- Fit `GridSearchCV` with the training data (`X_train_scaled`, `y_train`).\n",
    "- Access the best hyperparameter combination using `.best_params_`, the best score using `.best_score_`, and the best model using `.best_estimator_`\n",
    "- Evaluate the final model on the test set using `confusion_matrix` and `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Define hyperparameter grid\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "C = [0.01, 0.1, 1, 10]\n",
    "\n",
    "# Combine the lists into a dictionary\n",
    "hyperparameters = ...\n",
    "\n",
    "# Create logistic regression model\n",
    "lgr = ...\n",
    "\n",
    "# Use GridSearch\n",
    "grid_search = ...\n",
    "\n",
    "# Fit the model\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Best parameters, score (accuracy by default) and best model\n",
    "best_params = ...\n",
    "best_score = ...\n",
    "best_model = ...\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Best Model:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the final model\n",
    "y_pred = ...\n",
    "conf_matrix = ...\n",
    "classification_rpt = ...\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)  \n",
    "print(\"Classification Report:\\n\", classification_rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicated that the optimized hyperparameters did not yield a significant improvement in performance. This outcome suggests that the default hyperparameters for logistic regression were already well-suited for the given dataset. Alternatively, it could indicate that other factors, such as the data quality, feature selection, or the nature of the problem, might play a more critical role in improving the model's performance.\n",
    "\n",
    "This exercise reinforces the importance of testing and validating assumptions during the model optimization process. While hyperparameter tuning is a valuable tool, it is not always guaranteed to lead to better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Confusion Matrix and Classification Metrics\n",
    "\n",
    "A **confusion matrix** is a performance evaluation tool for classification models. It provides detailed insights into how well a classification algorithm performs, breaking down predictions into four categories:\n",
    "\n",
    "|                     | **Predicted Positive** | **Predicted Negative** |\n",
    "|---------------------|-------------------------|-------------------------|\n",
    "| **Actual Positive** | True Positive (TP)      | False Negative (FN)     |\n",
    "| **Actual Negative** | False Positive (FP)     | True Negative (TN)      |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Terms in the Confusion Matrix\n",
    "1. **True Positive (TP)**: The model correctly predicted a positive outcome.\n",
    "2. **True Negative (TN)**: The model correctly predicted a negative outcome.\n",
    "3. **False Positive (FP)**: The model predicted positive when it is actually negative (Type I error).\n",
    "4. **False Negative (FN)**: The model predicted negative when it is actually positive (Type II error).\n",
    "\n",
    "---\n",
    "\n",
    "### How to Calculate and Interpret Metrics\n",
    "Using the values from the confusion matrix, you can derive important classification metrics:\n",
    "\n",
    "#### 1. **Accuracy** \n",
    "   - **Formula**:  \n",
    "     \n",
    "     $${Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "     \n",
    "   - **Interpretation**: The percentage of all predictions (positive and negative) that are correct.\n",
    "   - **Limitation**: Can be misleading for imbalanced datasets (e.g., when one class dominates).\n",
    "\n",
    "#### 2. Precision (Positive Predictive Value)  \n",
    "   - **Formula**:  \n",
    "     \n",
    "     $${Precision} = \\frac{TP}{TP + FP}$$\n",
    "    \n",
    "   - **Interpretation**: Of all instances predicted as positive, how many are actually positive.\n",
    "   - **Importance**: High precision reduces false positives.\n",
    "\n",
    "#### 3. Recall (Sensitivity or True Positive Rate)  \n",
    "   - **Formula**:  \n",
    "   \n",
    "     $${Recall} = \\frac{TP}{TP + FN}$$\n",
    "  \n",
    "   - **Interpretation**: Of all actual positives, how many were correctly predicted.\n",
    "   - **Importance**: High recall reduces false negatives.\n",
    "\n",
    "#### 4. F1-Score (Harmonic Mean of Precision and Recall) \n",
    "   - **Formula**:  \n",
    "    \n",
    "     $${F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "    \n",
    "   - **Interpretation**: A balanced metric that considers both precision and recall. Useful for imbalanced datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluating Model Performance\n",
    "- **Single Accuracy**:\n",
    "  - Simpler but less informative for imbalanced datasets.\n",
    "  - Example: If 90% of data belongs to one class, a model predicting only that class achieves 90% accuracy without identifying any minority-class samples.\n",
    "\n",
    "- **Confusion Matrix**:\n",
    "  - Provides a detailed breakdown of correct and incorrect predictions.\n",
    "  - Helps calculate additional metrics like precision, recall, and F1-score to better evaluate model performance in complex scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### Example of Imbalanced Dataset\n",
    "- Dataset: 100 samples, 95 negatives, 5 positives.\n",
    "- Model predicts all negatives:\n",
    "  - Accuracy: 95% (good score).\n",
    "  - Recall: 0% for the positive class (poor performance).\n",
    "  \n",
    "Using only accuracy hides the model's inability to predict the minority class.\n",
    "\n",
    "---\n",
    "\n",
    "A **confusion matrix** and derived metrics like **precision**, **recall**, and **F1-score** provide a more comprehensive view of model performance than accuracy alone, especially in cases with imbalanced datasets or when certain types of errors (e.g., false positives or false negatives) are more costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "task1": {
     "name": "task1",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert data.shape[0] == 41188, 'Dataset should have 41188 rows. Please check if you loaded the correct dataset.'\n>>> assert data.shape[1] == 21, 'Dataset should have 21 columns. Please check if you loaded the correct dataset.'\n>>> assert head_data.shape[0] == 5, \"The 'head_data' should return exactly 5 rows. Ensure you are using the 'head()' function correctly.\"\n>>> assert data_description.equals(data.describe()), \"The function used to get summary of statistics is not correct. Ensure you use the 'describe()' method.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task2": {
     "name": "task2",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(missing_values, pd.Series), 'The output of `isnull().sum()` should be a pandas Series.'\n>>> assert missing_values.sum() == 0, 'Missing values count should be non-negative.'\n>>> assert len(data_shape) == 2, 'The shape should have two dimensions (rows, columns).'\n>>> assert data_shape[0] == 41188, 'The DataFrame should have at least one row.'\n>>> assert data_shape[1] == 21, 'The DataFrame should have at least one column.'\n>>> assert len(education_categories) == 8, 'The `education` column should contain 8 unique categories.'\n>>> assert list(education_categories) == ['basic.4y', 'unknown', 'university.degree', 'high.school', 'basic.9y', 'professional.course', 'basic.6y', 'illiterate']\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task3": {
     "name": "task3",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert y_value_counts.sum() == 41188, 'The sum of value counts should equal the total number of rows.'\n>>> assert y_value_counts[0] == 36548, 'The number of 0 class is not correct.'\n>>> assert y_value_counts[1] == 4640, 'The number of 1 class is not correct.'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> assert count_no_sub == 36548, 'Count of non-subscriptions is wrong.'\n>>> assert count_sub == 4640, 'Count of subscriptions is wrong.'\n>>> assert count_no_sub + count_sub == 41188, 'The sum of subscriptions and non-subscriptions should equal the total number of rows.'\n>>> assert pct_of_no_sub == 36548 / 41188, 'The value of pct_of_no_sub is wrong'\n>>> assert pct_of_sub == 4640 / 41188, 'The value of pct_of_sub is wrong'\n>>> assert np.isclose(pct_of_no_sub + pct_of_sub, 1), 'The sum of percentages should equal 100%.'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> expected_grouped_means = data.groupby('y').mean(numeric_only=True)\n>>> assert grouped_means.equals(expected_grouped_means), 'The output of `groupby().mean()` is not correct'\n>>> assert isinstance(grouped_means, pd.DataFrame), 'The output of `groupby().mean()` should be a pandas DataFrame.'\n>>> assert 'y' not in grouped_means.columns, \"The grouped DataFrame should not contain the 'y' column.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task5": {
     "name": "task5",
     "points": 30,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X.shape[0] == 41188, 'The number of rows in X should match the number of rows in data_final.'\n>>> assert y.shape[0] == 41188, 'The number of rows in y should match the number of rows in data_final.'\n>>> assert 'y' not in X.columns, \"'y' column should not be present in X.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> assert len(majority) == 25622, 'The majority class is empty.'\n>>> assert len(minority) == 3209, 'The minority class is empty.'\n>>> assert majority.shape[0] + minority.shape[0] == train_data.shape[0], 'The majority and minority classes do not sum up to the training data size.'\n>>> assert minority_upsampled.shape[0] == majority.shape[0], 'The number of upsampled minority class samples is not equal to the majority class.'\n>>> assert minority_upsampled.shape[0] > minority.shape[0], 'The minority class was not upsampled properly.'\n>>> assert majority.equals(train_data[train_data['y'] == 0]), 'wrong majority'\n>>> assert minority.equals(train_data[train_data['y'] == 1]), 'wrong minority'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> assert upsampled_data.shape[0] == majority.shape[0] + minority_upsampled.shape[0], 'The concatenated data has incorrect size.'\n>>> assert 'y' in upsampled_data.columns, \"The 'y' column is missing in the upsampled data.\"\n>>> assert 'y' not in X_train.columns, \"'y' should not be present in X_train.\"\n>>> assert y_train.shape[0] == upsampled_data.shape[0], \"The size of y_train doesn't match the number of rows in the upsampled data.\"\n>>> assert len(y_train[y_train == 0]) == len(y_train[y_train == 1]), 'The class distribution after upsampling is not balanced.'\n>>> assert set(y_train).issubset({0, 1}), 'The y_train variable contains values outside the expected 0 and 1 classes.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        },
        {
         "code": ">>> assert X_train_scaled.shape == X_train.shape, 'X_train_scaled should have the same shape as X_train'\n>>> assert X_test_scaled.shape == X_test.shape, 'X_test_scaled should have the same shape as X_test'\n>>> assert np.allclose(X_train_scaled.mean(axis=0), 0, atol=1e-07), 'Mean of scaled features in X_train_scaled should be close to 0'\n>>> assert np.allclose(X_train_scaled.std(axis=0), 1, atol=1e-07), 'Standard deviation of scaled features in X_train_scaled should be close to 1'\n>>> assert np.allclose((X_test - scaler.mean_) / scaler.scale_, X_test_scaled, atol=1e-07), 'X_test_scaled should be consistent with the scaling applied during fit on X_train'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task6": {
     "name": "task6",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hasattr(logreg, 'coef_'), 'The logistic regression model was not trained properly.'\n>>> assert round(accuracy, 2) == 0.85, 'The accuracy value is not correct.'\n>>> assert len(y_pred) == len(y_test), 'The number of predictions should match the number of test samples.'\n",
         "hidden": false,
         "locked": false,
         "points": 20
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task7": {
     "name": "task7",
     "points": 30,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hyperparameters == {'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'C': [0.01, 0.1, 1, 10]}, 'Hyperparameter dictionary is incorrect.'\n>>> assert isinstance(lgr, LogisticRegression), 'Logistic Regression model not instantiated correctly.'\n>>> assert isinstance(grid_search, GridSearchCV), 'GridSearchCV is not instantiated correctly.'\n>>> assert grid_search.param_grid == hyperparameters, 'Parameter grid is incorrect in GridSearchCV.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        },
        {
         "code": ">>> assert grid_search.best_params_ == best_params, 'Best parameters do not match GridSearchCV output.'\n>>> assert grid_search.best_score_ == best_score, 'Best score does not match GridSearchCV output.'\n>>> assert grid_search.best_estimator_ == best_model, 'Best model does not match GridSearchCV output.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        },
        {
         "code": ">>> assert y_pred.shape[0] == y_test.shape[0], 'Predictions shape does not match test data shape.'\n>>> assert conf_matrix[0][0] == 9296 or conf_matrix[0][1] == 1630 or conf_matrix[1][0] == 209 or (conf_matrix[1][1] == 1222), 'The values in confusion matrix are not correct.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
