{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c663b4",
   "metadata": {},
   "source": [
    "In the linear regression exercises, we have applied standard linear regression (Multi-variable) to the dataset `Advertising.csv`. Now, let's explore how regularized linear regression models (**Lasso** and **Ridge**) perform on the same dataset and some techniques to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1978215",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabde7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a07a3",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc41381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538e7f2",
   "metadata": {},
   "source": [
    "**Is there a siginficant improvement on metrics after regularization? List some reasons why this happens. If regularization does not give a better result, does it mean regularization is no use in this case? Please share your thoughts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae72aad",
   "metadata": {},
   "source": [
    "---\n",
    "In this exercise, Lasso regression does not perform very well compared to the other two models when using default hyperparameters of Lasso(). We can tune the hyperparameter to improve the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46836f84",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "\n",
    "There are two common methods for selecting the optimal hyperparameters:\n",
    "* **Grid Search**: Exhaustively searches through all hyperparameter combinations. It’s useful when you have a relatively small grid and want to explore all possible configurations.\n",
    "* **Randomized Search**: Samples a fixed number of hyperparameter combinations from the given space. It’s more efficient when the hyperparameter search space is large or when you don’t have enough computational resources to try every possible combination.\n",
    "\n",
    "For this example, we'll focus on using **RandomizedSearchCV** to improve the performance of **L1 regularized linear regression** (Lasso).\n",
    "\n",
    "\n",
    "Based on the documentation of [RandomizedSearchCV](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), documentation of [Lasso regression](https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Lasso.html), try to complete the step 2 and step 4 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# First, we need to import the required libraries for our task.\n",
    "# Lasso regression, RandomizedSearchCV, and evaluation metrics.\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, r2_score\n",
    "\n",
    "# Step 2: Define the parameter distributions for Lasso regression\n",
    "# Here, we define the hyperparameters and their possible values in a dictionary. \n",
    "# You can explore the Lasso regression documentation to find more details about the available hyperparameters \n",
    "# and their possible values. \n",
    "param_distributions = {\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Step 3: Initialize the Lasso regression model\n",
    "# We initialize the Lasso model here. This is the model we want to tune.\n",
    "lasso = Lasso()\n",
    "\n",
    "# Step 4: Set up RandomizedSearchCV\n",
    "# We use RandomizedSearchCV to search through different hyperparameter combinations.\n",
    "# RandomizedSearchCV will randomly select combinations from the parameter distributions and evaluate them using cross-validation.\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lasso,\n",
    "    param_distributions=param_distributions,\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "# Step 5: Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Display the best hyperparameters found by RandomizedSearchCV\n",
    "print(\"Best hyperparameters for Lasso Regression:\", random_search.best_params_)\n",
    "\n",
    "# Step 7: Get the best Lasso model after hyperparameter tuning\n",
    "best_lasso = random_search.best_estimator_\n",
    "\n",
    "y_pred_l1_best = best_lasso.predict(X_test)\n",
    "\n",
    "mse_l1_best = mean_squared_error(y_test, y_pred_l1_best)\n",
    "rmse_l1_best = np.sqrt(mse_l1_best)\n",
    "r2_l1_best = r2_score(y_test, y_pred_l1_best)\n",
    "\n",
    "print('\\nMetrices performance of tuned Lasso Regression')\n",
    "print(f\"Mean Squared Error: {mse_l1_best:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_l1_best:.2f}\")\n",
    "print(f\"R2 Score: {r2_l1_best:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fab09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
