{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Assignment4_SVM.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS385/CSD3185/CSD3186: Assignment 4 SVM\n",
    "\n",
    "## Deliverables\n",
    "Your submission for this assignment should be __ONE__ file - a zip file generated by the `grader.export(_)` function down below under 'Submission'. This function will auto create the zip file which contains this particular completed notebook file for you.  \n",
    "\n",
    "Subsequently, rename your zip file like this: __coursecode_A4_your_full_name.zip__  \n",
    "Eg. CS385_A4_john_doe.zip  \n",
    "\n",
    "To complete this assignment, you should follow instructions in Section Tasks.\n",
    "\n",
    "## IMPORTANT! READ THIS BEFORE STARTING...\n",
    "- DO NOT delete existing cells, but you can add more cells in between.\n",
    "- DO NOT modify the content of the existing cells unless otherwise stated.\n",
    "- Run the cell with `grader.check(_)` to check your solutions whenever you have completed each tasks.\n",
    "- Follow the file naming convention for the zip file as spelled out above strictly.\n",
    "- DO NOT rename this notebook file. It shall be 'assignment1.ipynb'. \n",
    "\n",
    "Please adhere strictly to the instructions as stated above as failure to do so might result in deduction of marks by the autograder.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Overview: Machine Learning Model Comparison\n",
    "\n",
    "In this assignment, you will apply **Support Vector Machines (SVM)** alongside previously learned machine learning modelsâ€”**Logistic Regression and Decision Tree**â€”to perform a comparative analysis. The goal is to evaluate and compare the performance of these models on a given dataset using various evaluation metrics. Through this process, you will gain a deeper understanding of how different classification algorithms perform under different conditions and learn to fine-tune models for optimal results.\n",
    "\n",
    "## Notebook Structure:\n",
    "Step 1: Data Loading & Cleaning [_2 marks_]\n",
    "\n",
    "Step 2: Exploratory Data Analysis (EDA) [_10 marks_]\n",
    "\n",
    "Step 3: Feature Engineering [_10 marks_]\n",
    "\n",
    "Step 4: Data Preprocessing & Feature Selection [_64 marks_]\n",
    "\n",
    "Step 5: Model Training & Selection [_14 marks_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Dataset (UCI)\n",
    "\n",
    "The Heart Disease dataset is a widely used dataset from the UCI Machine Learning Repository. It contains medical data used to predict the presence of heart disease in patients. The dataset consists of multiple patient attributes, including demographic, clinical, and laboratory test results.\n",
    "\n",
    "### Dataset Details  \n",
    "- **Number of Features:** 13  \n",
    "- **Target Variable:** `target` (1 = presence of heart disease, 0 = absence of heart disease)  \n",
    "- **Type:** Classification  \n",
    "\n",
    "### Features  \n",
    "| Feature | Description |\n",
    "|---------|------------|\n",
    "| `age` | Age of the patient (years) |\n",
    "| `sex` | Sex of the patient (1 = male, 0 = female) |\n",
    "| `cp` | Chest pain type (0-3, different types of angina and pain) |\n",
    "| `trestbps` | Resting blood pressure (mm Hg) |\n",
    "| `chol` | Serum cholesterol (mg/dL) |\n",
    "| `fbs` | Fasting blood sugar > 120 mg/dL (1 = true, 0 = false) |\n",
    "| `restecg` | Resting electrocardiographic results (0-2) |\n",
    "| `thalach` | Maximum heart rate achieved |\n",
    "| `exang` | Exercise-induced angina (1 = yes, 0 = no) |\n",
    "| `oldpeak` | ST depression induced by exercise relative to rest |\n",
    "| `slope` | Slope of the peak exercise ST segment (0-2) |\n",
    "| `ca` | Number of major vessels colored by fluoroscopy (0-3) |\n",
    "| `thal` | Thalassemia type (1 = normal, 2 = fixed defect, 3 = reversible defect) |\n",
    "| `target` | Presence of heart disease (1 = disease, 0 = no disease) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Data Loading & Cleaning\n",
    "**Tasks:**\n",
    "\n",
    "- Load the dataset and check for **duplicates**.\n",
    "\n",
    "- Remove duplicates (**1 duplicate exists** in `heart.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: 303\n",
      "Duplicate rows: 1\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "# Check duplicates\n",
    "print(\"Initial shape:\", df.shape[0])\n",
    "print(\"Duplicate rows:\", df.shape[0] - df.drop_duplicates().shape[0])  \n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! ðŸŒˆ</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trestbps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chol",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fbs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "restecg",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thalach",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exang",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "slope",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ca",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7f16f614-597e-494f-857c-3837ab717801",
       "rows": [
        [
         "0",
         "63",
         "1",
         "3",
         "145",
         "233",
         "1",
         "0",
         "150",
         "0",
         "2.3",
         "0",
         "0",
         "1",
         "1"
        ],
        [
         "1",
         "37",
         "1",
         "2",
         "130",
         "250",
         "0",
         "1",
         "187",
         "0",
         "3.5",
         "0",
         "0",
         "2",
         "1"
        ],
        [
         "2",
         "41",
         "0",
         "1",
         "130",
         "204",
         "0",
         "0",
         "172",
         "0",
         "1.4",
         "2",
         "0",
         "2",
         "1"
        ],
        [
         "3",
         "56",
         "1",
         "1",
         "120",
         "236",
         "0",
         "1",
         "178",
         "0",
         "0.8",
         "2",
         "0",
         "2",
         "1"
        ],
        [
         "4",
         "57",
         "0",
         "0",
         "120",
         "354",
         "0",
         "1",
         "163",
         "1",
         "0.6",
         "2",
         "0",
         "2",
         "1"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Exploratory Data Analysis (EDA)\n",
    "**Tasks:**\n",
    "\n",
    "- Plot a histogram of **age** with **20 bins**.\n",
    "\n",
    "- Plot **class distribution** of the target variable (**target**).\n",
    "\n",
    "- Visualize **correlations** between features and the target using a **heatmap**.\n",
    "\n",
    "- Identify **outliers** in **Cholesterol (chol)** and **ST depression (oldpeak)** using **boxplots**.\n",
    "\n",
    "Customize labels and titles for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histogram of age\n",
    "counts, bin_edges, _ = ...\n",
    "# Customize labels and titles\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Class distribution (countplot)\n",
    "ax_count = ...\n",
    "# Customize title\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "# Ensure each cell displays the correlation value (annot)\n",
    "# The values are formatted to one decimal place (fmt)\n",
    "ax = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outliers (boxplots)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "ax1 = ...\n",
    "plt.subplot(1, 2, 2)\n",
    "ax2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Engineering\n",
    "**Tasks:**\n",
    "\n",
    "- **Bin** `age` into groups: `<=45`, `45-55`, `>55`, labelled as **'young'**, **'middle'**, **'senior'**. (Hint: use pd.cut())\n",
    "\n",
    "- **Create interaction term** `age_chol` (**age Ã— cholesterol**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bin Age into Groups\n",
    "df['age_group'] = ...\n",
    "\n",
    "# Create Interaction Term\n",
    "df['age_chol'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Data Preprocessing & Feature Selection\n",
    "**Tasks:**\n",
    "\n",
    "- **Split Data** â†’ Features (`X`) & Target (`y`)  \n",
    "- **Train-Test Split** â†’ 80% train, 20% test, use `random_state = 42` and `stratify = y`\n",
    "- **Handle Outliers (Post Split!)** â†’ IQR capping 'for `chol` & `oldpeak`  \n",
    "- **One-Hot Encode** categorical variables (`cp, restecg, slope, thal, age_group`)  \n",
    "- **Standardize Numerical Features** â†’ `age, trestbps, chol, oldpeak, age_chol`  \n",
    "- **Feature Selection (RFE + Logistic Regression)** â†’ Keep top 10 features  (codes provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Data into Features (X) and Target (y)\n",
    "X = ...\n",
    "y = ...\n",
    "\n",
    "# Train-Test Split (80% Train, 20% Test)\n",
    "# Use random_state = 42 for reproducibility.\n",
    "# Use stratify = y to ensure the train and test sets have similar class distributions.\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing: Handling Outliers with IQR Method\n",
    "\n",
    "def calculate_outlier_bounds(df, columns):\n",
    "    \"\"\"\n",
    "    Calculate IQR-based outlier bounds using ONLY training data to prevent data leakage.\n",
    "    \n",
    "    IQR (Interquartile Range) Method:\n",
    "    - Q1 (25th percentile): The value below which 25% of the observations are found\n",
    "    - Q3 (75th percentile): The value below which 75% of the observations are found\n",
    "    - IQR = Q3 - Q1: The range of the middle 50% of the data\n",
    "    - Lower bound = Q1 - 1.5 * IQR: Values below this are considered outliers\n",
    "    - Upper bound = Q3 + 1.5 * IQR: Values above this are considered outliers\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The training DataFrame containing numerical columns\n",
    "    columns : list\n",
    "        List of column names to calculate IQR bounds for\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    bounds : dict\n",
    "        Dictionary with column names as keys and their corresponding lower/upper bounds\n",
    "    \"\"\"\n",
    "    # Initialize empty dictionary to store bounds for each column\n",
    "    bounds = {}\n",
    "   \n",
    "    \n",
    "    # Calculate bounds for each specified column\n",
    "    for col in columns:\n",
    "        ...\n",
    "        \n",
    "        # Store bounds for this column in the dictionary\n",
    "        bounds[col] = {\n",
    "            'lower': lower_bound,\n",
    "            'upper': upper_bound\n",
    "        }\n",
    "    \n",
    "    return bounds\n",
    "\n",
    "\n",
    "def apply_outlier_bounds(df, columns, bounds):\n",
    "    \"\"\"\n",
    "    Apply pre-calculated outlier bounds to a dataset (training or test).\n",
    "    \n",
    "    This function ensures we apply the SAME bounds to both training and test data,\n",
    "    preventing data leakage by not calculating new bounds from test data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to apply outlier capping to (can be training or test set)\n",
    "    columns : list\n",
    "        List of column names to apply outlier capping to\n",
    "    bounds : dict\n",
    "        Dictionary of pre-calculated bounds from training data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df_capped : pandas.DataFrame\n",
    "        A new DataFrame with outliers capped at the specified bounds\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_capped = df.copy()\n",
    "\n",
    "    # Apply capping to each specified column\n",
    "    for col in columns:\n",
    "        # Extract pre-calculated bounds for this column\n",
    "        lower_bound = ...\n",
    "        upper_bound = ...\n",
    "        \n",
    "        # Use np.clip to cap values at the lower and upper bounds\n",
    "        # - Values below lower_bound will be set to lower_bound\n",
    "        # - Values above upper_bound will be set to upper_bound\n",
    "        # - Values within the range remain unchanged\n",
    "        df_capped[col] = ...\n",
    "\n",
    "    return df_capped\n",
    "\n",
    "\n",
    "# STEP 1: Define columns that need outlier handling\n",
    "outlier_columns = ['chol', 'oldpeak']\n",
    "\n",
    "# STEP 2: Calculate bounds using ONLY training data\n",
    "outlier_bounds = ...\n",
    "\n",
    "# STEP 3:\n",
    "# Apply the bounds to training data\n",
    "X_train_capped = ...\n",
    "\n",
    "# Apply the SAME bounds to test data (prevents data leakage)\n",
    "X_test_capped = ...\n",
    "\n",
    "# IMPORTANT: Replace original dataframes with capped versions\n",
    "X_train = ...\n",
    "X_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Why it's better to use one-hot encoding here?**\n",
    "\n",
    "Even if categorical variables are converted to numbers (e.g., 0, 1, 2), ML models might misinterpret them as having mathematical meaning.\n",
    "\n",
    "**Problems with Numeric Encoding**:\n",
    "1. Ordinal vs. Nominal: Some categories have an order (ordinal), while others donâ€™t (nominal). Treating them as numbers can be misleading.\n",
    "2. False Mathematical Relationships: ML models may assume numerical significance (e.g., â€˜thalâ€™ = 3 is three times â€˜thalâ€™ = 1).\n",
    "3. Distance Misinterpretation: Algorithms like SVM use distances, leading to incorrect relationships between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding for Categorical Features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 1: Identify categorical features requiring one-hot encoding\n",
    "encoded_features = ['cp', 'restecg', 'slope', 'thal', 'ca', 'age_group']\n",
    "\n",
    "# Step 2: Initialize one-hot encoder (drop first category to avoid multicollinearity)\n",
    "# Set drop='first' removes one column per feature to avoid perfect multicollinearity\n",
    "# Set sparse_output = False, which is equivalent to calling .toarray()\n",
    "encoder = ...\n",
    "\n",
    "# Step 3: Fit on training data and transform both train and test sets\n",
    "# Create a DataFrame with proper column names for the encoded features \n",
    "# - encoder.fit_transform() learns categories from AND transforms training data\n",
    "# - encoder.get_feature_names_out() provides clear column names for the encoded features \n",
    "X_train_encoded = ...\n",
    "\n",
    "# Important: We only transform test data (not fit_transform) to prevent data leakage\n",
    "X_test_encoded = ...\n",
    "\n",
    "# Step 4: Identify remaining features (those not selected for one-hot encoding)\n",
    "remaining_features = ...\n",
    "\n",
    "# Step 5: Concatenate remaining features and one-hot encoded categorical features\n",
    "X_train = ...\n",
    "X_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardize Numerical Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = ...\n",
    "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'age_chol']\n",
    "\n",
    "X_train[numeric_features] = ...\n",
    "X_test[numeric_features] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to RFE (Recursive Feature Elimination) [Codes Provided]\n",
    "**Recursive Feature Elimination (RFE)** is a feature selection technique that helps identify the most important features for a machine learning model. It works by:\n",
    "\n",
    "1. **Training a model** on all features.\n",
    "2. **Ranking features** based on their importance (using model coefficients or feature importance scores).\n",
    "3. **Eliminating the least important feature(s)** and repeating the process until the desired number of features is reached.\n",
    "\n",
    "**Why use RFE?**\n",
    "\n",
    "- Reduces overfitting by removing irrelevant features.\n",
    "- Improves model interpretability.\n",
    "- Enhances computational efficiency.\n",
    "\n",
    "It is commonly used with models like **Logistic Regression**, **Decision Trees**, and **SVM** to optimize performance. In our example, we will use RFE with Logistic regression. \n",
    "\n",
    "The selected features are:\n",
    "```python\n",
    "['exang', 'cp_1', 'cp_2', 'cp_3', 'slope_1', 'thal_2', 'thal_3', 'ca_1', 'ca_2', 'ca_3']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using Recursive Feature Elimination (RFE)\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(model, n_features_to_select=10)  # Adjust based on desired number of features\n",
    "X_train_selected = rfe.fit_transform(X_train, y_train)\n",
    "X_test_selected = rfe.transform(X_test)  # Apply the same transformation to test set\n",
    "\n",
    "# Print selected feature indices\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f\"Selected Features: {selected_features.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Model Training & Selection\n",
    "**Tasks:**\n",
    "- Train and evaluate multiple classification models using `X_train_selected`, `X_test_selected`, `y_train`, and `y_test.`\n",
    "- Perform hyperparameter tuning using **GridSearchCV** to optimize model performance.\n",
    "- Select the best model based on **cross-validation score** and evaluate it on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize Models & Parameter Grids (codes provided)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter = 1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42)\n",
    "} \n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Step 2: Hyperparameter Tuning with Cross-validation\n",
    "best_models = {}\n",
    "cv_scores = {}  # Store cross-validation scores for each model\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nPerforming Grid Search for {name}\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        ...\n",
    "        ...\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit on training data\n",
    "    ...\n",
    "\n",
    "    # Store the best estimator\n",
    "    best_models[name] = ...\n",
    "    # Store the best cross-validation score\n",
    "    cv_scores[name] = ...\n",
    "\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {cv_scores[name]:.4f}\")\n",
    "\n",
    "# Step 3: Select the best model based on CV score\n",
    "best_model_name = max(cv_scores, key=cv_scores.get)  # Model with highest CV score\n",
    "# Retrieve the best trained model object from best_models dictionary\n",
    "best_model = ...\n",
    "\n",
    "print(f\"\\nBest model based on cross-validation: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Evaluate the Best Model on Test Data\n",
    "y_pred = ...\n",
    "\n",
    "test_accuracy = ...\n",
    "\n",
    "print(f\"\\nTest Accuracy of {best_model_name}: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "# print classification report\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curves to Check for Overfitting/Underfitting (codes provided)\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=5):\n",
    "    train_sizes_array = np.linspace(0.1, 1.0, 10)  # Renamed to avoid overwriting\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes_array, scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    # Compute mean and standard deviation for both training and validation scores\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # Plot learning curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot shaded areas representing standard deviation\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "    # Plot mean scores\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()  # Ensure the plot is displayed inside the function\n",
    "\n",
    "# Plot learning curve for the best model\n",
    "plot_learning_curve(best_model, f\"Learning Curve for {best_model_name}\", X_train_selected, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Interpret the Results**:\n",
    "\n",
    "- Overfitting: If there's a large gap between training score (red) and cross-validation score (green), with training score much higher\n",
    "- Underfitting: If both training and cross-validation scores are low and relatively close\n",
    "- Good fit: If both training and cross-validation scores are high and relatively close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert df.duplicated().sum() == 0, 'There should be no duplicates left after dropping them.'\n>>> assert df.shape[0] == 302 and df.shape[1], 'The shape of the dataset is not correct.'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(bin_edges) == 21, f'Expected 21 bin edges, got {len(bin_edges)}'\n>>> assert sum(counts) == len(df['age']), f'Expected {len(df['age'])}, but got {sum(counts)}'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> unique_values = set(df['target'].unique())\n>>> assert unique_values.issubset({0, 1}), f'Unexpected unique values in target: {unique_values}'\n>>> plot_counts = [p.get_height() for p in ax_count.patches]\n>>> actual_counts = df['target'].value_counts().sort_index().tolist()\n>>> assert np.array_equal(plot_counts, actual_counts), f'Mismatch: Expected {actual_counts}, got {plot_counts}'\n>>> x_labels = [t.get_text() for t in ax_count.get_xticklabels()]\n>>> expected_labels = sorted(df['target'].unique().tolist())\n>>> assert [int(label) for label in x_labels] == expected_labels, f'Expected {expected_labels}, got {x_labels}'\n>>> assert sum(plot_counts) == len(df['target']), f'Expected {len(df['target'])}, but got {sum(plot_counts)}'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> corr_matrix = df.corr()\n>>> heatmap_values = np.array([float(t.get_text()) for t in ax.texts]).reshape(corr_matrix.shape)\n>>> assert np.allclose(heatmap_values, corr_matrix.round(1)), f'Mismatch between heatmap annotations and computed correlations: {heatmap_values}'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> chol_values = [line.get_xdata()[0] for line in ax1.lines[:3]]\n>>> oldpeak_values = [line.get_xdata()[0] for line in ax2.lines[:3]]\n>>> chol_stats = df['chol'].describe()\n>>> oldpeak_stats = df['oldpeak'].describe()\n>>> assert np.allclose(chol_values, [chol_stats['25%'], chol_stats['75%'], chol_stats['min']]), \"Mismatch in boxplot statistics for 'chol'\"\n>>> assert np.allclose(oldpeak_values, [oldpeak_stats['25%'], oldpeak_stats['75%'], oldpeak_stats['min']]), \"Mismatch in boxplot statistics for 'oldpeak'\"\n",
         "hidden": false,
         "locked": false,
         "points": 4
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> expected_results = {44: 'young', 45: 'young', 50: 'middle', 55: 'middle', 56: 'senior'}\n>>> for age, expected_label in expected_results.items():\n...     actual_label = df[df['age'] == age]['age_group'].values[0]\n...     assert actual_label == expected_label, f'Test failed for age {age}: Expected {expected_label}, Got {actual_label}'\n>>> assert df['age_chol'][:5].tolist() == [14679, 9250, 8364, 13216, 20178], 'The calculation of age_chol column is wrong.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'target' not in X.columns, \"X should not contain the 'target' column\"\n>>> assert set(X.columns) == set(df.columns) - {'target'}, \"X should contain all columns from df except 'target'\"\n>>> assert y.name == 'target', \"y should be the 'target' column\"\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> sample_data = pd.DataFrame({'A': [10, 12, 15, 14, 200, 13, 12, 11, 300, 14], 'B': [100, 110, 120, 130, 125, 105, 115, 140, 150, 135]})\n>>> bounds = calculate_outlier_bounds(sample_data, ['A', 'B'])\n>>> lower_A, upper_A = (bounds['A']['lower'], bounds['A']['upper'])\n>>> lower_B, upper_B = (bounds['B']['lower'], bounds['B']['upper'])\n>>> Q1_A, Q3_A = (sample_data['A'].quantile(0.25), sample_data['A'].quantile(0.75))\n>>> IQR_A = Q3_A - Q1_A\n>>> expected_lower_A = Q1_A - 1.5 * IQR_A\n>>> expected_upper_A = Q3_A + 1.5 * IQR_A\n>>> Q1_B, Q3_B = (sample_data['B'].quantile(0.25), sample_data['B'].quantile(0.75))\n>>> IQR_B = Q3_B - Q1_B\n>>> expected_lower_B = Q1_B - 1.5 * IQR_B\n>>> expected_upper_B = Q3_B + 1.5 * IQR_B\n>>> assert lower_A == expected_lower_A and upper_A == expected_upper_A and (lower_B == expected_lower_B) and (upper_B == expected_upper_B), '`calculate_outlier_bounds` function does not work properly.'\n>>> bounds = calculate_outlier_bounds(sample_data, ['A', 'B'])\n>>> capped_df = apply_outlier_bounds(sample_data, ['A', 'B'], bounds)\n>>> lower_A, upper_A = (bounds['A']['lower'], bounds['A']['upper'])\n>>> assert all(lower_A <= capped_df['A']) and all(capped_df['A'] <= upper_A), 'Outliers were not capped correctly'\n>>> unchanged_values = sample_data['A'].between(lower_A, upper_A)\n>>> assert (sample_data['A'][unchanged_values] == capped_df['A'][unchanged_values]).all(), 'Non-outlier values should remain unchanged'\n>>> assert capped_df['A'].max() <= upper_A and capped_df['A'].min() >= lower_A, 'Bounds not applied correctly'\n>>> assert X_train_capped['chol'].max() == 366 and X_test_capped['chol'].max() == 366, 'Cholesterol (chol) should be capped at 366 for X_train and X_test after removing outliers. If your capped value is 376, please verify that you have correctly followed the train-test split instructions in the previous step.'\n>>> assert X_train_capped['oldpeak'].max() == 4.5 and X_test_capped['oldpeak'].max() == 3.6, 'oldpeal should be capped at 4.5 for X_train and X_test after removing outliers.'\n",
         "hidden": false,
         "locked": false,
         "points": 40
        },
        {
         "code": ">>> for col in encoded_features:\n...     assert col not in X_train.columns, f\"Original categorical column '{col}' still exists in training set\"\n...     assert col not in X_test.columns, f\"Original categorical column '{col}' still exists in test set\"\n>>> for col in remaining_features:\n...     assert col in X_train.columns, f\"Numerical column '{col}' is missing from training set\"\n...     assert col in X_test.columns, f\"Numerical column '{col}' is missing from test set\"\n>>> encoded_cols = ['cp_1', 'cp_2', 'cp_3', 'restecg_1', 'restecg_2', 'slope_1', 'slope_2', 'thal_1', 'thal_2', 'thal_3', 'ca_1', 'ca_2', 'ca_3', 'ca_4', 'age_group_senior', 'age_group_young']\n>>> train_encoded_values = X_train[encoded_cols].values.flatten()\n>>> test_encoded_values = X_test[encoded_cols].values.flatten()\n>>> assert set(np.unique(train_encoded_values)) <= {0, 1}, 'Training set encoded values are not binary'\n>>> assert set(np.unique(test_encoded_values)) <= {0, 1}, 'Test set encoded values are not binary'\n>>> assert X_train.shape[1] == 25, 'The shape of X_train after encoding is not correct'\n>>> assert X_test.shape[1] == 25, 'The shape of X_test after encoding is not correct'\n",
         "hidden": false,
         "locked": false,
         "points": 20
        },
        {
         "code": ">>> assert np.allclose(X_train[numeric_features].mean(), 0, atol=1e-07), 'Mean is not close to 0 in training set'\n>>> assert np.allclose(X_train[numeric_features].std(ddof=0), 1, atol=1e-07), 'Standard deviation is not close to 1 in training set'\n>>> assert not np.allclose(X_test[numeric_features].mean(), 0, atol=1e-07), 'Test set should not have mean 0 after transformation'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> expected_best_models_str = {'Logistic Regression': \"LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear')\", 'Decision Tree': 'DecisionTreeClassifier(max_depth=5, min_samples_split=10, random_state=42)', 'SVM': \"SVC(C=1, kernel='linear', probability=True, random_state=42)\"}\n>>> expected_cv_scores = {'Logistic Regression': round(0.8507653061224489, 4), 'Decision Tree': round(0.7930272108843538, 4), 'SVM': round(0.8549319727891156, 4)}\n>>> for key in expected_best_models_str:\n...     assert str(best_models[key]) == expected_best_models_str[key], f'Mismatch in best_models for {key}'\n>>> for key in expected_cv_scores:\n...     assert round(cv_scores[key], 4) == expected_cv_scores[key], f'Mismatch in cv_scores for {key}'\n",
         "hidden": false,
         "locked": false,
         "points": 12
        },
        {
         "code": ">>> assert round(test_accuracy, 4) == 0.7869, 'Test accuracy is not correct.'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
